# Выводы по заданию 5ого дня

1. Температура близкая к нулю выдает маловариативные ответы. Полезно при решении математических задач и при написании алгоритмов чего-либо (написание инструкций агентам, чтоб они им следовали не отходя от них). Пример: JSON-форматирование или XML-форматирование 2ого дня челленджа.

2. Температура близкая к середине полезна при решении инженерных задач, где немалую роль играет иногда нестандартный подход но в рамках и правилах какой-то системы координат (физический мир, язык программирования, использование определенных ингредиентов). Задача которая передается на решение агенту может являеться умеренно понятной человеку. Пример: форматирование текста в деловой стиль, человек точно знает что там не должно быть мата, но не знает наверняка в чем заключается деловой стиль письма.

3. Температура близка к 1 имеет высоковариативные ответы и подходит для решения творческих задач или задач, в которых человек слабо разбирается или не разбирается вообще. При высокой температуре модель не нуждается в готовой структуре, поэтому может сгенерировать направление для исследования даже там, где у человека нет экспертности. Такие задачи, как правило, почти не ограничены какой-то системой координат или инструкциями. Примеры таких задач: написание стихов, составление рецептов, написание MVP какого-то проекта.

# Вывод по заданию 6ого дня

Разные модели по-разному обучены на генерацию результатов. Генерация может отличаться как по времени так и по количеству токенов. 
В качестве сравнения были выбраны 3 модели: Sao10K/L3-8B-Stheno-v3.2, MiniMaxAI/MiniMax-M2:novita и Qwen/Qwen2.5-7B-Instruct. 
Qwen/Qwen2.5-7B-Instruct значительно лучшие результаты показала как по количеству токенов так и по времени запроса, однако обширность знаний показала лучше MiniMaxAI/MiniMax-M2:novita. 
Таким образом, можно сделать вывод что всегда будет что-то проседать и все зависит от LLM и целей которые перед ней ставятся. 
Треугольник: быстродействие, стоимость и качество ответа, всегда будет работать 2 из 3.